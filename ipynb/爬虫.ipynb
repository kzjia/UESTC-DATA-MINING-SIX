{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Host\": \"you.ctrip.com\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1='https://you.ctrip.com'\n",
    "#获取评论者信息\n",
    "def get_reviewer(url):\n",
    "    reviewer=[]\n",
    "    if url == 'https://you.ctrip.com':\n",
    "        return ['','','','']\n",
    "    else:\n",
    "        html = requests.get(url,timeout=20)\n",
    "        soup = BeautifulSoup(html.content,'html.parser')\n",
    "    \n",
    "        #名称信息\n",
    "        targets_1 = soup.find('span',class_=\"info-name\")\n",
    "    \n",
    "        name= targets_1.text\n",
    "        reviewer.append(name)\n",
    "    \n",
    "        #性别信息\n",
    "        targets_2 = soup.find('span',class_=\"J_gender\")\n",
    "        gender = targets_2.find('i')['class'][0]\n",
    "        reviewer.append(gender)\n",
    "    \n",
    "        #关注信息\n",
    "        target_3 = soup.find('div',class_=\"info-side\")\n",
    "        k=1\n",
    "        for string in target_3.stripped_strings:\n",
    "            if k%2 !=0:\n",
    "                reviewer.append(string)\n",
    "            k+=1\n",
    "        return(reviewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(poiID,n):\n",
    "    data=list()\n",
    "    for i in range(16,n+1):\n",
    "        url_raw=\"http://you.ctrip.com/destinationsite/TTDSecond/SharedView/AsynCommentView?poiID=\"+str(poiID)+\"&districtId=702&districtEName=Yangshuo&pagenow=%d&order=3.0&star=0.0&tourist=0.0&resourceId=22079&resourcetype=2\"\n",
    "        url=url_raw%(i)\n",
    "        html=requests.get(url,headers=headers)\n",
    "        html.encoding=\"utf-8\"\n",
    "        soup=BeautifulSoup(html.content)\n",
    "        block=soup.find_all(class_=\"comment_single\")\n",
    "        for j in block:\n",
    "            item=[] \n",
    "            \n",
    "            #评论者信息\n",
    "            url_Reviewer=j.find(itemprop=\"author\")['href']\n",
    "            Reviewer=get_reviewer(url_1+url_Reviewer)\n",
    "            \n",
    "            #评论文本\n",
    "            text=j.find(class_=\"heightbox\").text\n",
    "            \n",
    "            #星级\n",
    "            style=j.find('span',style =re.compile('width'))\n",
    "            \n",
    "            #评论时间\n",
    "            time = j.find(class_=\"time_line\").text\n",
    "            \n",
    "            #有用数\n",
    "            useful = j.find(class_=\"useful\").text\n",
    "            item=item+Reviewer\n",
    "            item.append(time)\n",
    "            item.append(style['style'])\n",
    "            item.append(text)\n",
    "            item.append(useful)\n",
    "            data.append(item)\n",
    "            \n",
    "    review_data=pd.DataFrame(data,columns=['name','gender','关注','粉丝','time','rating','text','useful'])\n",
    "    return(review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_data(10770546,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath='F:/太仓现代农业园16.csv'\n",
    "df.to_csv(outputpath,sep=',',index=True,header=True,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
